version: "3.4"
services:
  api:
    container_name: fastapi_server
    build: backend/.
    command: "uvicorn server:app --host 0.0.0.0 --port 8082 --reload"
    ports:    
      - "8082:8082"
      #- "5678:5678" # Debug
    volumes:
      - ./backend:/app/
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      PYTHONPATH: /app
    networks:
      - rag

  app:
    container_name: streamlit_app
    build: frontend/.
    command: "streamlit run --server.port 8080 --server.enableCORS false --server.enableXsrfProtection false Information.py"
    ports:
      - "8080:8080"
      - "5678:5678"
    environment:
      PYTHONPATH: /app
    volumes:
      - ./frontend:/app/
    networks:
      - rag

  redis:
    image: "redis/redis-stack:edge"
    ports:
      - "6379:6379"
      - "8001:8001"
    volumes:
      - ./docker-vols/redis:/data
    environment:
      REDIS_ARGS: --appendonly yes
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure

  weaviate:
    image: semitechnologies/weaviate:1.23.2
    container_name: weaviate_storage
    command: --host 0.0.0.0 --port '8083' --scheme http
    ports:
    - 8083:8083
    - 50051:50051
    volumes:
      - ./docker-vols/weaviate:/var/lib/weaviate
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: 'text2vec-openai,generative-openai'
      CLUSTER_HOSTNAME: 'node1'
    networks:
     - rag

networks:
  rag:
